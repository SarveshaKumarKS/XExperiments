# ==========================================
# Project X Environment Configuration
# ==========================================

# üîë OpenAI API Key (replace with your actual key)
OPENAI_API_KEY= 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
# üß† Default OpenAI model for flavor description generation
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1
# ‚öôÔ∏è Model parameters (adjust if needed)
OPENAI_TEMPERATURE=0.2
OPENAI_MAX_TOKENS=800

# üóÇÔ∏è Paths (relative to project_x root)
DATA_RAW=data_raw
DATA_CLEANED=data_cleaned
NOTEBOOKS=notebooks

# üíæ Caching configuration
LLM_CACHE_PATH=data_cleaned/llm_run_cache.jsonl
CHECKPOINT_INTERVAL=50    # Save CSV after every 50 rows

# üß© Output file names
LEXICON_FILE=data_cleaned/lexicon_llm.yaml
XD_VECTOR_FILE=data_cleaned/xd_vectors_from_llm.csv

# üß∞ Safety limits (optional)
MAX_API_CALLS=500         # Prevent runaway API charges
BATCH_SIZE=10             # Number of items processed per batch

# üïë Retry policy for LLM calls
RETRY_ATTEMPTS=5
RETRY_BACKOFF_MIN=1
RETRY_BACKOFF_MAX=30

# ==========================================
# END OF FILE
# ==========================================
